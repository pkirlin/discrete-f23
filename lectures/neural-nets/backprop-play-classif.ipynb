{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "1481d5f7-8c39-4d14-ac44-50fd471aa43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "d804ac70-ffea-41de-a183-2689d018ee3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.  0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.  1.1 1.2 1.3 1.4 1.5 1.6 1.7\n",
      " 1.8 1.9 2.  2.1 2.2 2.3 2.4 2.5 2.6 2.7 2.8 2.9] [-1.  -0.9 -0.8 -0.7 -0.6 -0.5 -0.4 -0.3 -0.2 -0.1 -0.   0.1  0.2  0.3\n",
      "  0.4  0.5  0.6  0.7  0.8  0.9  1.   1.1  1.2  1.3  1.4  1.5  1.6  1.7\n",
      "  1.8  1.9]\n"
     ]
    }
   ],
   "source": [
    "xarray1 = np.arange(0, 3, .1)\n",
    "xarray2 = np.arange(-1, 2, .1)\n",
    "print(xarray1, xarray2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "39fabcc0-e12f-4158-9055-d2b58abcfd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "yarray = (xarray1*xarray2 - 2*xarray1 + 1 > 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "7e28b9d6-155c-4005-9960-0d5c52e72977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 1])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "695f7492-1bc1-4558-aa25-37a249753b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.hstack([ np.ones((len(xarray1), 1)), np.reshape(xarray1, (-1, 1)) , np.reshape(xarray2, (-1, 1)) ] )\n",
    "#X_train = np.hstack([ np.reshape(xarray, (-1, 1))+1, np.reshape(xarray, (-1, 1)) ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "d567672e-f3e0-45cf-a1e8-1dd54bb556de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.   0.  -1. ]\n",
      " [ 1.   0.1 -0.9]\n",
      " [ 1.   0.2 -0.8]\n",
      " [ 1.   0.3 -0.7]\n",
      " [ 1.   0.4 -0.6]\n",
      " [ 1.   0.5 -0.5]\n",
      " [ 1.   0.6 -0.4]\n",
      " [ 1.   0.7 -0.3]\n",
      " [ 1.   0.8 -0.2]\n",
      " [ 1.   0.9 -0.1]\n",
      " [ 1.   1.  -0. ]\n",
      " [ 1.   1.1  0.1]\n",
      " [ 1.   1.2  0.2]\n",
      " [ 1.   1.3  0.3]\n",
      " [ 1.   1.4  0.4]\n",
      " [ 1.   1.5  0.5]\n",
      " [ 1.   1.6  0.6]\n",
      " [ 1.   1.7  0.7]\n",
      " [ 1.   1.8  0.8]\n",
      " [ 1.   1.9  0.9]\n",
      " [ 1.   2.   1. ]\n",
      " [ 1.   2.1  1.1]\n",
      " [ 1.   2.2  1.2]\n",
      " [ 1.   2.3  1.3]\n",
      " [ 1.   2.4  1.4]\n",
      " [ 1.   2.5  1.5]\n",
      " [ 1.   2.6  1.6]\n",
      " [ 1.   2.7  1.7]\n",
      " [ 1.   2.8  1.8]\n",
      " [ 1.   2.9  1.9]]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "85f0bb72-f8c4-448e-9ec2-92163fbb5a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = yarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "e8ff2e47-a261-4af6-8ccc-2fa576e563db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "e0c7dcf2-008e-4817-819c-1b211b781a7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 3) (30,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "246610d4-cdbd-4c92-b783-fe0066d97dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1/(1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "238623ae-fe2c-44f0-af0e-4be43146a9c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(activation=&#x27;logistic&#x27;, alpha=1e-05, hidden_layer_sizes=2,\n",
       "              random_state=1, solver=&#x27;lbfgs&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(activation=&#x27;logistic&#x27;, alpha=1e-05, hidden_layer_sizes=2,\n",
       "              random_state=1, solver=&#x27;lbfgs&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(activation='logistic', alpha=1e-05, hidden_layer_sizes=2,\n",
       "              random_state=1, solver='lbfgs')"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#input layer = one input (x1) plus bias x0\n",
    "#hidden layer = 2 nodes, x1 and x2, plus bias x0\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
    "                 hidden_layer_sizes=(2), random_state=1, activation='logistic')\n",
    "clf.fit(X_train[:, 1:], y_train)\n",
    "#clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "b6f49206-ac85-46c1-aaaa-818786bc62aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[-4.80206981, 29.29122937],\n",
      "       [32.36618305, 24.15338641]]), array([[ 26.72093158],\n",
      "       [-19.50466398]])]\n",
      "[array([-41.0987312 ,   4.57365195]), array([8.45312541])]\n"
     ]
    }
   ],
   "source": [
    "print(clf.coefs_)\n",
    "print(clf.intercepts_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "a3a373fe-cf5e-45f4-808d-0c23884ecb46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0006865896251668326"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.loss_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "14bbb987-51f5-42fb-a9c9-c4f66c2a97db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 1])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X_train[:, 1:])  # predict first 5 values in X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "d1608b5d-a074-40af-b927-ce92a425f98f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "41453565-e8ff-4c9c-9bf3-63dd43719061",
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = np.array([[-5.83749417, 1.61468679 ],[-0.45701456, 2.2893793 ]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "245c7f73-6835-471f-a5be-70aa78cd365b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  0. -1.]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 3 is different from 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[151], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(X_train[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m----> 2\u001b[0m \u001b[43mW1\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 3 is different from 2)"
     ]
    }
   ],
   "source": [
    "print(X_train[0])\n",
    "W1 @ X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fba8616e-4643-4e92-a1a2-dffec282e945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.   0.5 -0.5]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 3 is different from 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m a0 \u001b[38;5;241m=\u001b[39m X_train[\u001b[38;5;241m5\u001b[39m]\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(a0)\n\u001b[0;32m----> 3\u001b[0m a1 \u001b[38;5;241m=\u001b[39m sigmoid(\u001b[43mW1\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43ma0\u001b[49m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(a1)\n\u001b[1;32m      5\u001b[0m a1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39minsert(a1, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 3 is different from 2)"
     ]
    }
   ],
   "source": [
    "a0 = X_train[5]\n",
    "print(a0)\n",
    "a1 = sigmoid(W1 @ a0)\n",
    "print(a1)\n",
    "a1 = np.insert(a1, 0, 1)\n",
    "print(a1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7308d93f-6183-44f0-b09a-ba9a45e1c9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "W2 = np.array([2.62995857, 10.49068236, -4.41164907])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "70280296-8b6b-4544-9c50-e00c1c378991",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'a1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m a2 \u001b[38;5;241m=\u001b[39m sigmoid(W2 \u001b[38;5;241m@\u001b[39m \u001b[43ma1\u001b[49m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(a2)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'a1' is not defined"
     ]
    }
   ],
   "source": [
    "a2 = sigmoid(W2 @ a1)\n",
    "print(a2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "14866415-2ec4-4c91-950e-a3fa27dc7e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3)\n",
      "(1, 3)\n"
     ]
    }
   ],
   "source": [
    "### START HERE\n",
    "\n",
    "# Network will have 2 inputs.   (not counting bias)  LAYER 0\n",
    "# Middle/hidden will have 2 nodes.  (not counting bias)  LAYER 1\n",
    "# output will have 1 node (not counting bias).  LAYER 2\n",
    "\n",
    "# 2 layers total, (with 1 input layer=layer 0).  numbered 0-2\n",
    "\n",
    "# So W1 is dimensions 2 (from hidden layer) by 2 (from input layer), but input is actually \n",
    "# 3 inputs because of bias.  so W1 will be 2x3. (2 rows, 3 cols)\n",
    "\n",
    "W1 = np.random.rand(2, 3)\n",
    "\n",
    "# W2 is dimensions 1 (from output) by 2 (from hidden), but add extra column for bias.\n",
    "# So W2 is 1 by 3.\n",
    "\n",
    "W2 = np.random.rand(1, 3)\n",
    "\n",
    "print(W1.shape)\n",
    "print(W2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "904ed64c-8866-481e-a3a0-e9060e630a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_z_vector(W, input_vector):\n",
    "    return W @ input_vector\n",
    "\n",
    "def compute_activation_vector(z_vector):\n",
    "    return sigmoid(z_vector)\n",
    "\n",
    "def augment_vector(v):\n",
    "    return np.insert(v, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "e43b2664-e074-4adb-a7af-20abe90ea361",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 2, 3])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augment_vector(np.array([1, 2, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "ebd0545d-2fcc-4478-ab88-e8a42939b87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_prop(all_W, one_input):\n",
    "    # we assume one_input doesn't have the 1 in front.\n",
    "    activations = []\n",
    "    z_vectors = [None]  # no z0, so put this in here as a placeholder\n",
    "    inputs = [None]\n",
    "    \n",
    "    # set a0\n",
    "    activations.append(one_input)\n",
    "    \n",
    "    # for each layer, compute z, compute activation:\n",
    "    for layer in range(1, len(all_W)):\n",
    "        print(\"In layer\", layer)\n",
    "        \n",
    "        # get activation of previous layer\n",
    "        activation_prev_layer = activations[layer-1]\n",
    "        print(\"Activation of prev layer\", layer-1, \"is\", activation_prev_layer)\n",
    "        \n",
    "        # augment the output of previous layer with a 1\n",
    "        inputs.append(augment_vector(activation_prev_layer))\n",
    "        print(\"Input to this layer is\", inputs[layer])\n",
    "        \n",
    "        # get W matrix\n",
    "        W = all_W[layer]\n",
    "        print(\"Using W of shape\", W.shape)\n",
    "        \n",
    "        # compute z\n",
    "        z_this_layer = compute_z_vector(W, inputs[layer])\n",
    "        print(\"z is\", z_this_layer)\n",
    "        z_vectors.append(z_this_layer)\n",
    "        \n",
    "        # compute activation\n",
    "        activation_this_layer = compute_activation_vector(z_this_layer)\n",
    "        print(\"activation is\", activation_this_layer)\n",
    "        activations.append(activation_this_layer)\n",
    "    \n",
    "    return inputs, z_vectors, activations\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "fbb98288-e9df-4546-8e03-337892d673fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In layer 1\n",
      "Activation of prev layer 0 is [ 0. -1.]\n",
      "Input to this layer is [ 1.  0. -1.]\n",
      "Using W of shape (2, 3)\n",
      "z is [ 0.55185398 -0.63296395]\n",
      "activation is [0.63456562 0.34683878]\n",
      "In layer 2\n",
      "Activation of prev layer 1 is [0.63456562 0.34683878]\n",
      "Input to this layer is [1.         0.63456562 0.34683878]\n",
      "Using W of shape (1, 3)\n",
      "z is [1.43252744]\n",
      "activation is [0.80729482]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([None, array([ 1.,  0., -1.]), array([1.        , 0.63456562, 0.34683878])],\n",
       " [None, array([ 0.55185398, -0.63296395]), array([1.43252744])],\n",
       " [array([ 0., -1.]), array([0.63456562, 0.34683878]), array([0.80729482])])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward_prop([None, W1, W2], X_train[0, 1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "946833c2-e72b-4e66-b6bf-29635c3e1135",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cross_entropy_one_example(y, yhat):\n",
    "    return -y*np.log(yhat) - (1-y)*np.log(1 - yhat)\n",
    "\n",
    "def cross_entropy_derivative(y, yhat):\n",
    "    return (yhat - y)/(yhat * (1-y))\n",
    "\n",
    "def compute_mse_one_example(y, yhat):\n",
    "    return .5 * (yhat - y) ** 2\n",
    "\n",
    "def mse_derivative(y, yhat):\n",
    "    return (yhat - y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "70330c12-3830-4264-bb9e-6a38e658beb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In layer 1\n",
      "Activation of prev layer 0 is [ 0. -1.]\n",
      "Input to this layer is [ 1.  0. -1.]\n",
      "Using W of shape (2, 3)\n",
      "z is [ 0.55185398 -0.63296395]\n",
      "activation is [0.63456562 0.34683878]\n",
      "In layer 2\n",
      "Activation of prev layer 1 is [0.63456562 0.34683878]\n",
      "Input to this layer is [1.         0.63456562 0.34683878]\n",
      "Using W of shape (1, 3)\n",
      "z is [1.43252744]\n",
      "activation is [0.80729482]\n",
      "activation is [0.80729482]\n",
      "cost is [0.21406636]\n"
     ]
    }
   ],
   "source": [
    "example_x = X_train[0, 1:]\n",
    "example_y = y_train[0]\n",
    "inputs, z, a = forward_prop([None, W1, W2], example_x)\n",
    "print(\"activation is\", a[-1])\n",
    "example_yhat = a[-1]\n",
    "\n",
    "print(\"cost is\", compute_cost_one_example(example_y, example_yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "dc824058-88b9-42ec-907b-938af44d7aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = compute_mse_one_example\n",
    "deriv_loss_fn = mse_derivative\n",
    "\n",
    "def deriv_activation_fn(z):\n",
    "    return sigmoid(z) * (1-sigmoid(z))\n",
    "\n",
    "def backprop(all_W, y, yhat, inputs, z_vectors, activations):\n",
    "    num_layers = len(all_W)-1\n",
    "    dC_dz = [None] * (num_layers+1)  # 0 through L, 0 will be ignored\n",
    "    dC_dz[0] = None\n",
    "    dC_dW = [None] * (num_layers+1)  # 0 through L, 0 will be ignored\n",
    "    dC_dW[0] = None\n",
    "    #dC_dz = np.zeros((num_layers),)  # 0 through L, 0 will be ignored\n",
    "    \n",
    "    # redo:\n",
    "    deltas = [None] * (num_layers+1)\n",
    "    loss_derivs = [None] * (num_layers+1)\n",
    "    activation_derivs = [None] * (num_layers+1)\n",
    "    \n",
    "    print(\"number of layers is\", num_layers)\n",
    "    #print(\"dC/dz\", dC_dz)\n",
    "    #print(\"dC/dW\", dC_dW)\n",
    "    \n",
    "    # init last layer things\n",
    "    #dC_dz[num_layers] = activations[num_layers] - y\n",
    "    #print(\"dC/dz\", dC_dz)\n",
    "    #print(\"SSS\",dC_dz[num_layers],np.transpose(activations[num_layers - 1]))\n",
    "    #dC_dW[num_layers] = np.dot(dC_dz[num_layers], np.transpose(activations[num_layers - 1]))\n",
    "    #print(\"dC/dW\", dC_dW)\n",
    "    \n",
    "    # init last layer things\n",
    "    loss_derivs[num_layers] = deriv_loss_fn(y, activations[num_layers])   #y, yhat\n",
    "    print(\"y, yhat\", y, yhat)\n",
    "    activation_derivs[num_layers] = deriv_activation_fn(z_vectors[num_layers])\n",
    "    deltas[num_layers] = loss_derivs[num_layers] * activation_derivs[num_layers]\n",
    "    print(\"delta at output\", deltas)\n",
    "    \n",
    "    for layer in range(len(all_W)-2, 0, -1):\n",
    "        print(\"backprop at layer\", layer)\n",
    "        this_delta = activation_derivs[num_layers] @ deltas[layer+1]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "cfc807ba-2752-4a19-a0f3-435a89348692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In layer 1\n",
      "Activation of prev layer 0 is [ 0. -1.]\n",
      "Input to this layer is [ 1.  0. -1.]\n",
      "Using W of shape (2, 3)\n",
      "z is [ 0.55185398 -0.63296395]\n",
      "activation is [0.63456562 0.34683878]\n",
      "In layer 2\n",
      "Activation of prev layer 1 is [0.63456562 0.34683878]\n",
      "Input to this layer is [1.         0.63456562 0.34683878]\n",
      "Using W of shape (1, 3)\n",
      "z is [1.43252744]\n",
      "activation is [0.80729482]\n",
      "activation. is [0.80729482]\n",
      "number of layers is 2\n",
      "y, yhat 1 [0.80729482]\n",
      "delta at output [None, None, array([-0.02997913])]\n",
      "backprop at layer 1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 1 is different from 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[212], line 9\u001b[0m\n\u001b[1;32m      5\u001b[0m example_yhat \u001b[38;5;241m=\u001b[39m a[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      7\u001b[0m compute_cost_one_example(example_y, example_yhat)\n\u001b[0;32m----> 9\u001b[0m \u001b[43mbackprop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW2\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_yhat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[211], line 40\u001b[0m, in \u001b[0;36mbackprop\u001b[0;34m(all_W, y, yhat, inputs, z_vectors, activations)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(all_W)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbackprop at layer\u001b[39m\u001b[38;5;124m\"\u001b[39m, layer)\n\u001b[0;32m---> 40\u001b[0m     this_delta \u001b[38;5;241m=\u001b[39m \u001b[43mall_W\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlayer\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdeltas\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlayer\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 1 is different from 3)"
     ]
    }
   ],
   "source": [
    "example_x = X_train[0, 1:]\n",
    "example_y = y_train[0]\n",
    "inputs, z, a = forward_prop([None, W1, W2], example_x)\n",
    "print(\"activation. is\", a[-1])\n",
    "example_yhat = a[-1]\n",
    "\n",
    "compute_cost_one_example(example_y, example_yhat)\n",
    "\n",
    "backprop([None, W1, W2], example_y, example_yhat, inputs, z, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "18e78944-2cb7-4d15-8394-760499277cff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9, 16])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([3, 4]) * np.array([3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "51f125ab-638c-4cb6-8cb3-ad1ee217da72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x, y, z):\n",
    "    return (x+y) * z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "55d77575-4334-4e4e-bb38-f73bfbef7c7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-12"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(-2, 5, -4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "4d9190f3-40f7-408a-a3b5-98e082ba3096",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-16"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(-2, 6, -4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5260b03-cfbe-4da9-b356-af8ea06d025a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
